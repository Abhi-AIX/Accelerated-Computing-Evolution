# The Evolution of Accelerated Computing

**Author:** Abhi (Abhi AIX)  
**Topics:** AI Hardware, GPUs, TPUs, Accelerators, AI Infrastructure, ML Systems

---

## Overview

This repository contains my research-style paper on how accelerated computing has evolved over the last three decades, and how it powers the future of artificial intelligence.

I explore how major tech companies â€” **NVIDIA, AMD, Apple, Google, Meta, Tesla, Amazon, and Intel** â€” are building custom chips and AI accelerators to support deep learning, language models, and autonomous systems.

## Key Topics Covered

- Timeline of GPU/TPU/NPU advancements from 1993 to 2025
- Company-specific architectures (Tensor Cores, MI300, TPUs, Dojo, MTIA, etc.)
- Shift from CPUs to parallel computing in AI
- Developer ecosystems (CUDA, ROCm, TensorFlow, PyTorch, etc.)
- Economic & industry impact
- Future outlook and challenges

## ðŸ“¢ Also Published On Medium

-  [Read on Medium]
-  ([https://medium.com/your-article-link](https://medium.com/@aibhi.dev/the-evolution-of-accelerated-computing-how-nvidia-amd-apple-google-others-are-powering-the-469d437c91ce))  
